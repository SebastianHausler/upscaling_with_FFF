import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms
from fff.loss import fff_loss
from PIL import Image
import os
import numpy as np

class ConvBlock(nn.Module):
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)
        self.norm = nn.BatchNorm2d(out_channels)
        self.activation = nn.SiLU()

    def forward(self, x):
        return self.activation(self.norm(self.conv(x)))

class FreeFormFlow(nn.Module):
    def __init__(self, in_channels=3, latent_dim=256, out_channels=3, scale_factor=4):
        super().__init__()
        self.latent_dim = latent_dim
        self.scale_factor = scale_factor
        
        # Encoder
        self.encoder = nn.Sequential(
            ConvBlock(in_channels, 64),
            nn.MaxPool2d(2),
            ConvBlock(64, 128),
            nn.MaxPool2d(2),
            ConvBlock(128, 256),
            nn.MaxPool2d(2),
            nn.Flatten(),
            nn.Linear(256 * 8 * 8, latent_dim)
        )
        
        # Decoder
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, 256 * 8 * 8),
            nn.Unflatten(1, (256, 8, 8)),
            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),
            ConvBlock(256, 128),
            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),
            ConvBlock(128, 64),
            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),
            ConvBlock(64, 32),
            nn.Conv2d(32, out_channels, kernel_size=3, padding=1),
            nn.Tanh()
        )
        
        self.latent_distribution = torch.distributions.Normal(
            loc=torch.zeros(latent_dim),
            scale=torch.ones(latent_dim)
        )

    def forward(self, x):
        z = self.encoder(x)
        return self.decoder(z)

    def to(self, device):
        super().to(device)
        self.latent_distribution.loc = self.latent_distribution.loc.to(device)
        self.latent_distribution.scale = self.latent_distribution.scale.to(device)
        return self

class DIV2KDataset(Dataset):
    def __init__(self, hr_dir, crop_size=256, scale_factor=0.25):
        self.hr_dir = hr_dir
        self.crop_size = crop_size
        self.scale_factor = scale_factor
        self.image_files = [f for f in os.listdir(hr_dir) if f.endswith('.png')]
        self.transform = transforms.Compose([
            transforms.RandomCrop(crop_size),
            transforms.ToTensor(),
        ])

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        img_name = self.image_files[idx]
        hr_img = Image.open(os.path.join(self.hr_dir, img_name))
        
        hr_img = self.transform(hr_img)
        
        lr_size = int(self.crop_size * self.scale_factor)
        lr_img = F.interpolate(hr_img.unsqueeze(0), size=(lr_size, lr_size), mode='bicubic', align_corners=False).squeeze(0)

        return lr_img, hr_img

def custom_collate(batch):
    lr_imgs, hr_imgs = zip(*batch)
    lr_imgs = torch.stack(lr_imgs)
    hr_imgs = torch.stack(hr_imgs)
    return lr_imgs, hr_imgs

if __name__ == "__main__":
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # Datensatz und DataLoader
    train_hr_dir = 'C:/Users/Admin/Desktop/DIV2K_train_HR'
    val_hr_dir = 'C:/Users/Admin/Desktop/DIV2K_valid_HR'
    train_dataset = DIV2KDataset(train_hr_dir, crop_size=256, scale_factor=0.25)
    val_dataset = DIV2KDataset(val_hr_dir, crop_size=256, scale_factor=0.25)
    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4, collate_fn=custom_collate)
    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4, collate_fn=custom_collate)

    # Modell, Optimierer und andere Hyperparameter
    model = FreeFormFlow(scale_factor=4).to(device)
    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)
    n_epochs = 50
    beta = 1.0

    # Training Loop
    for epoch in range(n_epochs):
        model.train()
        train_loss = 0
        for batch in train_loader:
            low_res, high_res = batch
            low_res, high_res = low_res.to(device), high_res.to(device)
            
            optimizer.zero_grad()
            
            loss = fff_loss(
                low_res, 
                model.encoder, 
                lambda z: F.interpolate(model.decoder(z), size=low_res.shape[2:], mode='bilinear', align_corners=False),
                model.latent_distribution, 
                beta,
                hutchinson_samples=1
            )
            
            output = model(low_res)
            output_resized = F.interpolate(output, size=high_res.shape[2:], mode='bilinear', align_corners=False)
            mse_loss = F.mse_loss(output_resized, high_res)
            total_loss = loss.mean() + mse_loss
            
            total_loss.backward()
            optimizer.step()
            
            train_loss += total_loss.item()
        
        train_loss /= len(train_loader)
        print(f"Epoch {epoch+1}/{n_epochs}, Train Loss: {train_loss:.4f}")

    torch.save(model.state_dict(), 'final_fff_upscaler.pth')